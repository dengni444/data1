{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n",
      "12.1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)    #æŸ¥çœ‹cpuç‰ˆæœ¬\n",
    "print(torch.version.cuda)\n",
    "     #æŸ¥çœ‹gpuç‰ˆæœ¬\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''å¤šé‡å›¾ï¼šfriendè¾¹ã€visitè¾¹ã€revisitè¾¹ã€co-occå…±ç°è¾¹ã€live-withè¾¹ã€classè¾¹\n",
    "ç†è®ºä¸Šéƒ½æ˜¯æœ‰å‘å›¾\n",
    "æœ‰çš„æ˜¯å¯¹ç§°è¾¹ï¼Œæœ‰çš„æ˜¯éå¯¹ç§°è¾¹ï¼Œå¯¹ç§°è¾¹æœ¬ä»£ç ä¸­åªè®°å½•å…¶ä¸­ä¸€åŠ\n",
    "æŠŠä¸€å¤©åˆ†ä¸ºå››æ®µ 22-5 5-10 10-15 15-22  éœ€è¦embedding\n",
    "friendè¾¹æ˜¯å¯¹ç§°è¾¹ï¼Œè¾¹ç‰¹å¾å®šä¹‰ä¸º  meetingæ¬¡æ•°åœ¨å››ä¸ªä¸åŒæ—¶é—´æ®µï¼Œå’Œå®¶ä¹‹é—´çš„è·ç¦» ç‰¹å¾æ•°5\n",
    "visitè¾¹æ˜¯éå¯¹ç§°è¾¹ï¼Œè¾¹ç‰¹å¾å®šä¹‰ä¸º  å››ä¸ªä¸åŒæ—¶é—´æ®µåˆ†åˆ«çš„è®¿é—®æ¬¡æ•°  æ— åˆ™ä¸ºå¡«0  ç‰¹å¾æ•°4\n",
    "revisitè¾¹æ˜¯éå¯¹ç§°è¾¹ï¼Œè¾¹ç‰¹å¾å®šä¹‰ä¸º å››ä¸ªä¸åŒæ—¶é—´æ®µåˆ†åˆ«çš„è®¿é—®æ¬¡æ•°  æ— åˆ™ä¸ºå¡«0  ç‰¹å¾æ•°4 ä¸visitè¾¹å¯¹ç§° ä½†æ˜¯èµ·å§‹ç‚¹å’Œç»ˆç‚¹çš„node typeä¸ä¸€æ ·\n",
    "co-occå…±ç°è¾¹æ˜¯å¯¹ç§°è¾¹ å¦‚æœä¸¤ä¸ªpoiåœ¨ä¸€ä¸ªç”¨æˆ·çš„å†å²è½¨è¿¹ä¸­å‡ºç°ï¼Œåˆ™è®¾ä¸º1ï¼Œå¤šå‡ºç°äº†å‡ æ¬¡ï¼Œåˆ™+n, ä»¥åŠä¸¤ç‚¹ä¹‹é—´çš„è·ç¦» ç‰¹å¾æ•°2\n",
    "live-withæ˜¯å¦‚æœpoiåœ¨ç”¨æˆ·çš„å®¶ğŸ æ—è¾¹1.5KM,è®¾ä¸º1 ç‰¹å¾æ•°1\n",
    "re_live_withè¾¹\n",
    "classè¾¹ æ˜¯å¯¹ç§°è¾¹ï¼Œ  poiä¸Šçš„ç±»åˆ«æ•°æœ€å¤šä½ä¸º3                               å¦‚æœä¸¤ä¸ªpoiæ˜¯åŒç±»ï¼Œåˆ™è®¾ä¸º1, ä¸¤ä¸ªç‚¹ä¹‹é—´çš„è·ç¦»  ç‰¹å¾æ•°2\n",
    "'''\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "def distance(origin, destination):  # è®¡ç®—ç»çº¬åº¦ç‚¹ä¹‹é—´çš„è·ç¦»\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "    return d  # è¿”å›çš„æ˜¯km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=\"TKY\"\n",
    "path=\"FourSquare/Data_cut_city/follow_mat/\"+city+\"/\"\n",
    "\n",
    "check_in=pd.read_csv(path+\"checkins_\"+city.lower()+\"_follow_mat.csv\")\n",
    "poi_data=pd.read_csv(path+\"POI_\"+city.lower()+\"_follow_mat.csv\")   #ç›®å‰å­˜åœ¨çš„é—®é¢˜æ˜¯check_inçš„ç”¨æˆ·å°‘\n",
    "friend_old=pd.read_csv(\"dataset_WWW2019/dataset_WWW_friendship_old.txt\",sep='\\t',header=None)\n",
    "friend_new=pd.read_csv(\"dataset_WWW2019/dataset_WWW_friendship_new.txt\",sep='\\t',header=None)\n",
    "friend_old.columns = ['user1','user2']\n",
    "friend_new.columns = ['user1','user2']\n",
    "\n",
    "\n",
    "print(check_in)\n",
    "print(poi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_check_in=set(list(check_in['userid']))  #ä»check_inå‡ºæ¥ï¼Œæ‰¾åˆ°check_inä¹‹åå†å»æ‰¾userå’Œfriend_ship   3754\n",
    "print(\"ä¸€å…±æœ‰\",len(user_check_in),\"ä¸ªuserå­˜åœ¨check_in\")\n",
    "\n",
    "print(user_check_in)\n",
    "\n",
    "\n",
    "venue_check_in=set(list(check_in['Venue_id']))   #ä»check_inå‡ºæ¥ æ‰¾POI\n",
    "print(\"ä¸€å…±æœ‰\",len(venue_check_in),\"ä¸ªVenueå­˜åœ¨check_in\")\n",
    "\n",
    "friend=pd.concat([friend_old,friend_new]) #æŠŠnewå’Œoldç»“åˆèµ·æ¥\n",
    "friend.drop_duplicates(subset=['user1','user2'],keep='first',inplace=True)\n",
    "friend = friend.reset_index(drop=True)  #é‡æ–°è®¾ç½®ç´¢å¼•  #701317 rows Ã— 2 columns å…¨é‡çš„friendshipå…³ç³»\n",
    "\n",
    "friend_list=[] #\n",
    "for index,row in friend.iterrows():\n",
    "    if row['user1'] in user_check_in and row['user2'] in user_check_in:\n",
    "        if row['user1']!=row['user2']: #æœ‹å‹å…³ç³»è¾¹ ä¸¤è¾¹ä¸èƒ½æ˜¯åŒä¸€ä¸ªäºº\n",
    "            friend_list.append([row['user1'],row['user2']])\n",
    "#         friend_list.append([row['user2'],row['user1']])#å¯¹ç§°è¾¹\n",
    "\n",
    "#print(friend_list)\n",
    "\n",
    "print(\"userä¹‹é—´ä¸€å…±æœ‰\",len(friend_list),\"æ¡è¾¹\")\n",
    "user=[]\n",
    "for i in range(len(friend_list)):\n",
    "    user.append(friend_list[i][0])\n",
    "    user.append(friend_list[i][1])\n",
    "print(\"ä¸€å…±æœ‰\",len(set(user)),\"ä¸ªuserå­˜åœ¨å¥½å‹å…³ç³»\")\n",
    "print(user)\n",
    "print(\"æœ‰\",len(user_check_in)-len(set(user)),\"ä¸ªè‡ªé—­ç—‡æ‚£è€…ï¼Œä¸å’Œè¿™3811  ä¸ªç”¨æˆ·ä¹‹é—´å­˜åœ¨å¥½å‹å…³ç³»\")\n",
    "print(friend_list[:10]) #å°±æ˜¯åŸå§‹çš„æœ‹å‹å…³ç³»å¯¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#å»ºç«‹ç´¢å¼•\n",
    "'''å»ºç«‹ç´¢å¼•ï¼Œä½¿ç”¨å­—å…¸''' '''å†è½¬æˆçŸ©é˜µå½¢å¼'''  # ç”¨æˆ· useréœ€è¦ç´¢å¼•ï¼Œpoiä¹Ÿéœ€è¦ç´¢å¼•\n",
    "import os\n",
    "\n",
    "\n",
    "user_check_in_sort = list(sorted(list(user_check_in)))  # TKY ç”¨æˆ·è¡¨\n",
    "# print(user_check_in_sort)\n",
    "\n",
    "user_dic = {}  # {ç”¨æˆ·id: user_index}  ç”¨æˆ·çš„ç´¢å¼•\n",
    "for i in range(len(user_check_in_sort)):\n",
    "    user_dic[user_check_in_sort[i]] = i\n",
    "\n",
    "    \n",
    "    \n",
    "   #########\n",
    "a=set(list(poi_data['category']))   #ä»check_inå‡ºæ¥ æ‰¾POI\n",
    "A = list(sorted(list(a)))  # TKY ç”¨æˆ·è¡¨\n",
    "# # print(user_check_in_sort)\n",
    "AA_CAT = {}  # {ç”¨æˆ·id: user_index}  ç”¨æˆ·çš„ç´¢å¼•\n",
    "for i in range(len(A)):\n",
    "    AA_CAT[A[i]] = i\n",
    "\n",
    "\n",
    "print(AA_CAT)\n",
    "########\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(user_dic)\n",
    "    \n",
    "    \n",
    "venue_check_in_sort = list(sorted(list(venue_check_in)))  # TKY POIè¡¨\n",
    "Venue_id_dic = {}  # {POIid: poi_index} POIç´¢å¼•\n",
    "for i in range(len(venue_check_in_sort)):\n",
    "    Venue_id_dic[venue_check_in_sort[i]] = i\n",
    "    \n",
    "# print(Venue_id_dic)\n",
    "\n",
    "friend_list_index = []  # å¥½å‹å…³ç³»{user1_indexï¼šuser2_index} å¥½å‹ #å¯¹ç§°\n",
    "for i in range(len(friend_list)):\n",
    "    friend_list_index.append((user_dic[friend_list[i][0]], user_dic[friend_list[i][1]]))\n",
    "print(friend_list_index[:10])\n",
    "\n",
    "\n",
    "# æ–‡ä»¶ä¿å­˜è·¯å¾„\n",
    "save_path = \"data/Multi-dimensional_Graphs/\" + city\n",
    "\n",
    "# ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# ä¿å­˜å¥½å‹å…³ç³»ç´¢å¼•\n",
    "np.save(os.path.join(save_path, \"friend_list_index.npy\"), torch.tensor(np.array(friend_list_index)).t().contiguous())\n",
    "#print( torch.tensor(np.array(friend_list_index)).t().contiguous())\n",
    "#np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/friend_list_index.npy\",torch.tensor(np.array(friend_list_index)).t().contiguous())  #ä¿å­˜ friend listè¾¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=set(list(poi_data['category']))   #ä»check_inå‡ºæ¥ æ‰¾POI\n",
    "A = list(sorted(list(a)))  # TKY ç”¨æˆ·è¡¨\n",
    "# # print(user_check_in_sort)\n",
    "AA_CAT = {}  # {ç§ç±»id: user_index}  ç”¨æˆ·çš„ç´¢å¼•\n",
    "for i in range(len(A)):\n",
    "    AA_CAT[A[i]] = i\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ä¿®æ”¹poiâ€”â€”data\n",
    "poi_data['Venue_id_index']=None\n",
    "poi_data['category_index']=None\n",
    "for index, row in poi_data.iterrows():  #æŠŠpoiæ•°æ®ä¸­çš„Venueidæ¢æˆpoiç´¢å¼•\n",
    "    poi_data['Venue_id_index'][index]=Venue_id_dic[row['Venue_id']]\n",
    "    poi_data['category_index'][index]=AA_CAT[row['category']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'Caf' in row['category']:\n",
    "        if len(row['category'])==5 or len(row['category'])==4 :\n",
    "            poi_data['category'][index]='caf\\u00e9'    \n",
    "poi_data=poi_data.sort_values('Venue_id', ascending=True, inplace=False )\n",
    "poi_data=poi_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "print(poi_data)\n",
    "\n",
    "\n",
    "poi_lat_lon={} #{poi_index:(lat,lon)}\n",
    "for index, row in poi_data.iterrows(): \n",
    "    poi_lat_lon[index]=(row['latitude'],row['longitude'])\n",
    "   \n",
    "\n",
    "cat={} #{poi_index:(lat,lon)}\n",
    "cat1={}\n",
    "for index, row in poi_data.iterrows(): \n",
    "    cat[index]=row['category']\n",
    "    cat1[index]=row['category_index']\n",
    "\n",
    "# poi_data\n",
    "#print(poi_data)\n",
    "#print(poi_lat_lon)\n",
    "\n",
    "#ä¿®æ”¹check-inæ•°æ®\n",
    "def time_fenge(hour): #å–å€¼åŒºé—´ä¸º[0,23]  æŠŠä¸€å¤©åˆ†ä¸º4æ®µ \n",
    "    #æŠŠä¸€å¤©åˆ†ä¸ºå››æ®µ 22-5 5-10 10-15 15-22  éœ€è¦embedding\n",
    "    if 5<=hour<10:\n",
    "        return 1\n",
    "    elif 10<=hour<15:\n",
    "        return 2\n",
    "    elif 15<=hour<22:\n",
    "        return 3\n",
    "    elif 22<=hour or hour<5 :\n",
    "        return 0\n",
    "\n",
    "import time\n",
    "check_in=check_in.sort_values('Venue_id', ascending=True, inplace=False ) #å°†åŸå§‹çš„checkinæ ¹æ®poiæ’åº\n",
    "check_in=check_in.reset_index(drop=True)\n",
    "check_in['unix_time']=None  #æŠŠcheck in ä¸­çš„utcæ—¶é—´å˜æˆunixæ—¶é—´æˆ³ æœªåŠ æ—¶åŒº\n",
    "check_in['userid_index']=None \n",
    "check_in['Venue_id_index']=None\n",
    "check_in['loacl_time_year']=None\n",
    "check_in['loacl_time_mon']=None #æœˆ #æœˆä»½ï¼ˆä»ä¸€æœˆå¼€å§‹ï¼Œ0ä»£è¡¨ä¸€æœˆï¼‰ - å–å€¼åŒºé—´ä¸º[0,11] */\n",
    "check_in['loacl_time_mday']=None #ä¸€ä¸ªæœˆä¸­çš„æ—¥æœŸ - å–å€¼åŒºé—´ä¸º[1,31] */\n",
    "check_in['loacl_time_hour']=None #æ—¶ - å–å€¼åŒºé—´ä¸º[0,23]\n",
    "check_in['loacl_time_min']=None #åˆ† - å–å€¼åŒºé—´ä¸º[0,59]\n",
    "check_in['loacl_time_sec']=None\n",
    "check_in['loacl_time_wday']=None  #æ˜ŸæœŸ â€“ å–å€¼åŒºé—´ä¸º[0,6]ï¼Œå…¶ä¸­0ä»£è¡¨æ˜ŸæœŸä¸€ï¼Œ1ä»£è¡¨æ˜ŸæœŸäºŒï¼Œä»¥æ­¤ç±»æ¨ */\n",
    "check_in['hour_periods']=None\n",
    "check_in['lat_lon']=None\n",
    "\n",
    "\n",
    "check_in_unix_time=[]\n",
    "check_in_userid_index=[]\n",
    "check_in_Venue_id_index=[]\n",
    "check_in_loacl_time_year=[]\n",
    "check_in_loacl_time_mon=[]\n",
    "check_in_loacl_time_mday=[]\n",
    "check_in_loacl_time_hour=[]\n",
    "check_in_loacl_time_min=[]\n",
    "check_in_loacl_time_sec=[]\n",
    "check_in_loacl_time_wday=[]\n",
    "check_in_hour_periods=[]\n",
    "check_in_lat_lon=[]\n",
    "\n",
    "\n",
    "catt=[]\n",
    "\n",
    "catt22=[]\n",
    "for index,row in check_in.iterrows():\n",
    "    time_1=row['utc_time'][:-10]+row['utc_time'][-4:]\n",
    "    Timezone_offset=row['Timezone_offset']\n",
    "    struct_time = time.mktime(time.strptime(time_1, \"%a %b %d  %H:%M:%S %Y\"))+((Timezone_offset))*60 #å½“åœ°æ—¶é—´æˆ³ å·²ç»åŠ ä¸Šäº†æ—¶åŒºä¿¡æ¯ \n",
    "    localtime = time.localtime(struct_time)  #è¿”å›å…ƒç»„\n",
    "    \n",
    "    \n",
    "    check_in_unix_time.append(struct_time)\n",
    "\n",
    "    check_in_loacl_time_year.append(localtime[0])\n",
    "    check_in_loacl_time_mon.append(localtime[1])\n",
    "    check_in_loacl_time_mday.append(localtime[2])\n",
    "    check_in_loacl_time_hour.append(localtime[3]) #å°æ—¶\n",
    "    check_in_loacl_time_min.append(localtime[4])\n",
    "    check_in_loacl_time_sec.append(localtime[5])\n",
    "    check_in_loacl_time_wday.append(localtime[6])\n",
    "    check_in_hour_periods.append(time_fenge(localtime[3]))\n",
    "\n",
    "    check_in_userid_index.append(user_dic[row['userid']])\n",
    "    check_in_Venue_id_index.append(Venue_id_dic[row['Venue_id']])\n",
    "    check_in_lat_lon.append( poi_lat_lon[Venue_id_dic[row['Venue_id']]])\n",
    "    \n",
    "    \n",
    "    catt.append( cat[Venue_id_dic[row['Venue_id']]])\n",
    "    \n",
    "    catt22.append( cat1[Venue_id_dic[row['Venue_id']]])\n",
    "    \n",
    "    \n",
    "check_in['unix_time'] =check_in_unix_time\n",
    "check_in['userid_index']=check_in_userid_index\n",
    "check_in['Venue_id_index']=check_in_Venue_id_index\n",
    "check_in['loacl_time_year']=check_in_loacl_time_year\n",
    "check_in['loacl_time_mon']=check_in_loacl_time_mon #æœˆ #æœˆä»½ï¼ˆä»ä¸€æœˆå¼€å§‹ï¼Œ0ä»£è¡¨ä¸€æœˆï¼‰ - å–å€¼åŒºé—´ä¸º[0,11] */\n",
    "check_in['loacl_time_mday']=check_in_loacl_time_mday #ä¸€ä¸ªæœˆä¸­çš„æ—¥æœŸ - å–å€¼åŒºé—´ä¸º[1,31] */\n",
    "check_in['loacl_time_hour']=check_in_loacl_time_hour #æ—¶ - å–å€¼åŒºé—´ä¸º[0,23]\n",
    "check_in['loacl_time_min']=check_in_loacl_time_min #åˆ† - å–å€¼åŒºé—´ä¸º[0,59]\n",
    "check_in['loacl_time_sec']=check_in_loacl_time_sec\n",
    "check_in['loacl_time_wday']=check_in_loacl_time_wday \n",
    "check_in['hour_periods']=check_in_hour_periods\n",
    "check_in['lat_lon']=check_in_lat_lon\n",
    "\n",
    "\n",
    "check_in['category']=catt\n",
    "check_in['category_id']=catt22\n",
    "\n",
    "# å‡è®¾ä½ è¦ä» DataFrame ä¸­åˆ é™¤åä¸º 'column_name' çš„åˆ—\n",
    "check_in.drop(columns=['cat_index'], inplace=True)\n",
    "\n",
    "check_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_in\n",
    "\n",
    "check_in.to_csv('FourSquare/Data_cut_city/follow_mat/TKY/df_tky_check_in_cid.csv',encoding=\"utf_8_sig\",index=False) #ä¿å­˜ä¸œäº¬checkin_æ ¹æ®matæ•°æ®ç¡®å®šuserå’Œvenueid  # 698889 rows Ã— 4 columns\n",
    "poi_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è®¾ä½ è¦å°† 'old_column_name' æ›´æ”¹ä¸º 'new_column_name'\n",
    "poi_data.rename(columns={'category_index': 'category_id'}, inplace=True)\n",
    "poi_data\n",
    "poi_data.to_csv('FourSquare/Data_cut_city/follow_mat/TKY/df_tky_poi_data_cid.csv',encoding=\"utf_8_sig\",index=False) #ä¿å­˜ä¸œäº¬checkin_æ ¹æ®matæ•°æ®ç¡®å®šuserå’Œvenueid  # 698889 rows Ã— 4 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_in\n",
    "\n",
    "#check_in.to_csv('FourSquare/Data_cut_city/follow_mat/TKY/df_tky_check_in.csv',encoding=\"utf_8_sig\",index=False) #ä¿å­˜ä¸œäº¬checkin_æ ¹æ®matæ•°æ®ç¡®å®šuserå’Œvenueid  # 698889 rows Ã— 4 columns\n",
    "poi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_data\n",
    "  # åŸæ¥æœ‰7232 å®é™…ä¸Š7219\n",
    "#poi_data.to_csv('FourSquare/Data_cut_city/follow_mat/TKY/df_tky_poi_data.csv',encoding=\"utf_8_sig\",index=False) #ä¿å­˜ä¸œäº¬checkin_æ ¹æ®matæ•°æ®ç¡®å®šuserå’Œvenueid  # 698889 rows Ã— 4 columns\n",
    "len(set(list(poi_data['category'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visit_list = []\n",
    "\n",
    "for index, row in check_in.iterrows():\n",
    "    visit_list.append((row['userid_index'],row['Venue_id_index']))\n",
    "    # visit_list.append((user_dic[row['userid']], Venue_id_dic[row['Venue_id']]))\n",
    "print(visit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŠŠç­¾åˆ°å…³ç³» è½¬æˆè¾¹ user å’Œ poiçš„è¾¹ æœ‰å‘å›¾\n",
    "# visitè¾¹æ˜¯éå¯¹ç§°è¾¹ï¼Œè¾¹ç‰¹å¾å®šä¹‰ä¸º  å››ä¸ªä¸åŒæ—¶é—´æ®µåˆ†åˆ«çš„è®¿é—®æ¬¡æ•°  æ— åˆ™ä¸ºå¡«0  ç‰¹å¾æ•°4\n",
    "# revisitè¾¹æ˜¯éå¯¹ç§°è¾¹ï¼Œè¾¹ç‰¹å¾å®šä¹‰ä¸º å››ä¸ªä¸åŒæ—¶é—´æ®µåˆ†åˆ«çš„è®¿é—®æ¬¡æ•°  æ— åˆ™ä¸ºå¡«0  ç‰¹å¾æ•°4 ä¸visitè¾¹å¯¹ç§° ä½†æ˜¯èµ·å§‹ç‚¹å’Œç»ˆç‚¹çš„node typeä¸ä¸€æ ·\n",
    "\n",
    "def get_index(lst=None, item=''):  #Pythonä»åˆ—è¡¨ä¸­æ‰¾å‡ºæ‰€æœ‰å…ƒç´ ç´¢å¼•çš„æ–¹æ³•\n",
    "    return [index for (index,value) in enumerate(lst) if value == item]\n",
    "\n",
    "visit_list = []\n",
    "\n",
    "for index, row in check_in.iterrows():\n",
    "    visit_list.append((row['userid_index'],row['Venue_id_index']))\n",
    "    # visit_list.append((user_dic[row['userid']], Venue_id_dic[row['Venue_id']]))\n",
    "    \n",
    "visit_list_edge=list(sorted(list(set(visit_list))))   #çœ‹ä¸€å…±æœ‰å¤šå°‘ä¸ªè®¿é—®åºåˆ—çš„è¾¹\n",
    "re_visit_list_edge=[]\n",
    "for (user,poi) in visit_list_edge:\n",
    "    re_visit_list_edge.append((poi,user)) #revisitåˆ‡æ¢èµ·å§‹ä¸é‡ç‚¹çš„å€¼\n",
    "\n",
    "visit_list_hour_per=[]\n",
    "for index, row in check_in.iterrows():\n",
    "    visit_list_hour_per.append((row['userid_index'],row['Venue_id_index'],row['hour_periods']))\n",
    "\n",
    "#ç”¨æˆ·è®¿é—®POIçš„è¾¹çš„ç‰¹å¾  ç”¨æˆ·çš„å†å²è®¿é—®æ¬¡æ•°\n",
    "visit_list_edge_attr=[]\n",
    "\n",
    "for i in range(len(visit_list_edge)):\n",
    "    index_=get_index(visit_list,visit_list_edge[i])\n",
    "    cishu=len(index_) #æ€»æ¬¡æ•°\n",
    "    edge_hour=[0,0,0,0]\n",
    "    for j in index_:\n",
    "        a=visit_list_hour_per[j][2]\n",
    "        edge_hour[a]+=1  #ç»Ÿè®¡æ¯ä¸ªæ—¶é—´æ®µçš„æ¬¡æ•°\n",
    "#     cishu=visit_list.count(visit_list_edge[i]) #ä¸éœ€è¦æ€»æ¬¡æ•°äº†\n",
    "#     visit_list_edge_attr.append(cishu) #do not need any more\n",
    "    visit_list_edge_attr.append(edge_hour)\n",
    "re_visit_list_edge_attr=visit_list_edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/visit_list_edge_tensor.npy\",torch.tensor(np.array(visit_list_edge)).t().contiguous()) #user -> visit -> poi å•å‘è¾¹\n",
    "np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/visit_list_edge_attr.npy\",torch.tensor(np.array(visit_list_edge_attr))) #user -> visit -> poi å•å‘è¾¹ç‰¹å¾ ä¸åŒæ—¶é—´æ®µçš„è®¿é—®æ¬¡æ•°\n",
    "np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/revisit_list_edge_tensor.npy\",torch.tensor(np.array(re_visit_list_edge)).t().contiguous()) #poi -> revisit -> user å•å‘è¾¹\n",
    "np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/revisit_list_edge_attr.npy\",torch.tensor(np.array(re_visit_list_edge_attr))) #poi -> revisit -> user å•å‘è¾¹ç‰¹å¾ ä¸åŒæ—¶é—´æ®µçš„è®¿é—®æ¬¡æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_in2 = check_in.sort_values('userid_index', ascending=True, inplace=False)  # å°†åŸå§‹çš„checkinæ ¹æ®poiæ’åº\n",
    "group = check_in2.groupby(\"userid_index\")  # åˆ†ç»„\n",
    "group = list(group)\n",
    "print(group[0])\n",
    "user_home={} #ç”¨æˆ·å®¶çš„ä½å€\n",
    "for i in range(len(group)):\n",
    "    userid=group[i][0]\n",
    "    df = pd.DataFrame(group[i][1])\n",
    "    df = df.reset_index(drop=True)\n",
    "    user_loc=df['lat_lon']\n",
    "    lat=[]\n",
    "    lon=[]\n",
    "    for (lat1,lon1) in list(user_loc):\n",
    "        lat.append(lat1)\n",
    "        lon.append(lon1)\n",
    "    lat_aver=np.mean(lat) #userçš„ç­¾åˆ°ç‚¹çš„å¹³å‡ä¸ºå®¶ä½å®…\n",
    "    lon_aver=np.mean(lon)\n",
    "    user_home[i]=(lat_aver,lon_aver)\n",
    "user_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''æœ¬æ®µä»£ç è¿è¡Œéœ€è¦14åˆ†é’Ÿ'''\n",
    "#friend è¾¹çš„meetingå…³ç³» \n",
    "#friendè¾¹æ˜¯å¯¹ç§°è¾¹ï¼Œè¾¹ç‰¹å¾å®šä¹‰ä¸º  meetingæ¬¡æ•°åœ¨å››ä¸ªä¸åŒæ—¶é—´æ®µï¼Œå’Œå®¶ä¹‹é—´çš„è·ç¦» ç‰¹å¾æ•°5\n",
    "group = check_in.groupby(\"Venue_id\")   #åˆ†ç»„\n",
    "group=list(group)\n",
    "meeting_Threshold=1800*2  # å•ä½ç§’ s å…±0.5h 1h  1800sæ˜¯0.5h \n",
    "#1h ç®—è§é¢çš„é˜ˆå€¼\n",
    "friend_list_dict_attr={} \n",
    "for i in range(len(friend_list_index)):\n",
    "#     print(friend_list)\n",
    "    index_friend=str(friend_list_index[i][0]) + str(\"+\")+str(friend_list_index[i][1])\n",
    "    friend_list_dict_attr[index_friend]=[0,0,0,0,0] #åˆå§‹åŒ– 5ç»´ç‰¹å¾\n",
    "    \n",
    "for i in range(len(group)):\n",
    "#     print(i)  \n",
    "    df=pd.DataFrame(group[i][1])  #æ¯ä¸€ä¸ªgroupæ˜¯ä¸€ä¸ªè®¿é—®è¿‡åŒä¸€poiçš„ä¸åŒç”¨æˆ·çš„äºº\n",
    "    df=df.reset_index(drop=True)\n",
    "    for index,row in df.iterrows():\n",
    "        for index2,row2 in df.iterrows():\n",
    "            if index !=index2:\n",
    "                if abs(row['unix_time']-row2['unix_time'])< meeting_Threshold: #ä¸¤ä¸ªäººåœ¨0.5å°æ—¶å†…ç›¸èšåœ¨åŒä¸€POI\n",
    "                    if (row['userid_index'],row2['userid_index']) in friend_list_index : #å¦‚æœä¸¤ä¸ªäººè§é¢äº†å¹¶ä¸”ä»–ä»¬æ˜¯æœ‹å‹\n",
    "                        hour_per=row['hour_periods'] \n",
    "                        friend_list_dict_attr[str(row['userid_index'])+str(\"+\")+str(row2['userid_index'])][hour_per]+=1\n",
    "                    elif (row2['userid_index'],row['userid_index']) in friend_list_index:  #friend_list_index å®é™…ä¸Šæ˜¯åŒå‘è¾¹ï¼Œä½†æ˜¯è¿™é‡Œä¸ºäº†æ–¹ä¾¿åªä¿å­˜äº†å•å‘çš„ç»“æœ\n",
    "                        hour_per=row['hour_periods'] \n",
    "                        friend_list_dict_attr[str(row2['userid_index'])+str(\"+\")+str(row['userid_index'])][hour_per]+=1\n",
    "    \n",
    "friend_edge_attr=[]\n",
    "for i in range(len(friend_list_index)): #æŠŠuser_indexç‰ˆæœ¬çš„ç‰¹å¾æŒ‰ç…§è¾“å…¥dataä¸­çš„è¾¹çš„é¡ºåºé‡ç»„\n",
    "    dis=distance(user_home[friend_list_index[i][0]] , user_home[friend_list_index[i][1]]) \n",
    "    friend_list_dict_attr[str(friend_list_index[i][0]) + str(\"+\")+str(friend_list_index[i][1])][4]=dis  #è®¡ç®—ä¸¤ä¸ªuserå®¶ä¹‹é—´çš„è·ç¦»\n",
    "    \n",
    "    friend_edge_attr.append(friend_list_dict_attr[str(friend_list_index[i][0])+str(\"+\")+str(friend_list_index[i][1])])\n",
    "    \n",
    "friend_edge_attr= (np.array(friend_edge_attr))\n",
    "print(friend_edge_attr)\n",
    "np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/friend_edge_attr.npy\",friend_edge_attr)  #ç‰¹å¾æ•°5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''poi åˆ°user è¿˜æœ‰live_withå…³ç³»ï¼Œå¦‚æœpoiè·ç¦»userçš„å®¶è¿‘ 1.5km''' \n",
    "def POi_live_with_user(poi_data,user_home):  #poi åˆ°userçš„è¾¹ï¼Œpoiåœ¨å‰\n",
    "    live_with = []\n",
    "    live_with_attr=[]\n",
    "    re_live_with = []\n",
    "    re_live_with_attr=[]\n",
    "    for i in range(len(\tuser_home.keys())):\n",
    "        (lat_user,lon_user)=user_home[i] #userçš„ç­¾åˆ°ç‚¹çš„å¹³å‡ä¸ºå®¶ä½å®…\n",
    "        for index, row in poi_data.iterrows():\n",
    "            dis=distance((lat_user,lon_user),(row['latitude'],row['longitude']))\n",
    "            if dis<=1.5 : #1.5å…¬é‡Œä»¥å†…\n",
    "                live_with.append((row['Venue_id_index'],i)) # poi åˆ°userçš„è¾¹ï¼Œpoiåœ¨å‰\n",
    "                re_live_with.append((i,row['Venue_id_index'])) # user åˆ°poi çš„è¾¹ï¼Œuseråœ¨å‰\n",
    "                live_with_attr.append(dis)\n",
    "                re_live_with_attr.append(dis)\n",
    "    live_with=np.array(live_with)\n",
    "    re_live_with=np.array(re_live_with)\n",
    "#     live_with_attr=np.ones((live_with.shape[0],1))\n",
    "    live_with=torch.tensor(live_with,dtype=torch.long).t().contiguous()\n",
    "    re_live_with=torch.tensor(re_live_with,dtype=torch.long).t().contiguous()\n",
    "    live_with_attr=np.array(live_with_attr).reshape(-1,1)\n",
    "    re_live_with_attr=np.array(re_live_with_attr).reshape(-1,1)\n",
    "    return live_with,live_with_attr,re_live_with,re_live_with_attr\n",
    "\n",
    "live_with_edge,live_with_attr,re_live_with_edge,re_live_with_attr =POi_live_with_user(poi_data,user_home)\n",
    "np.save(\"../data/Multi-dimensional_Graphs/\"+city+\"/live_with_edge.npy\",live_with_edge)\n",
    "np.save(\"../data/Multi-dimensional_Graphs/\"+city+\"/live_with_attr.npy\",live_with_attr)\n",
    "np.save(\"../data/Multi-dimensional_Graphs/\"+city+\"/re_live_with_edge.npy\",re_live_with_edge)\n",
    "np.save(\"../data/Multi-dimensional_Graphs/\"+city+\"/re_live_with_attr.npy\",re_live_with_attr)\n",
    "live_with_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''poi ä¸poi ä¹‹é—´çš„å…³ç³» å…±ç°å…³ç³»ä¸åŒç±»å…³ç³»'''\n",
    "#å…ˆå¤„ç†åŒç±»å…³ç³» \n",
    "def POi_class_same_POI(poi_data):  #poi ä¸poiåŒç±»å³å¯æœ‰è¾¹    ç›´æ¥å­˜å‚¨çš„å°±æ˜¯åŒå‘è¾¹ï¼Œ\n",
    "    class_same_edge=[]\n",
    "    class_same_edge_attr=[]\n",
    "    for index, row in poi_data.iterrows():\n",
    "        print(index)\n",
    "        for index2,row2 in poi_data.iterrows():\n",
    "            \n",
    "            if index!=index2:\n",
    "#                 if (row['cat0_0']==row2['cat0_0']) or (row['cat0_1']==row2['cat0_1']) or (row['cat0_2']==row2['cat0_2']) \\\n",
    "#                 or (row['cat1_0']==row2['cat1_0']) or (row['cat1_1']==row2['cat1_1']) or (row['cat1_2']==row2['cat1_2']) \\\n",
    "#                 or (row['cat2_0']==row2['cat2_0']) or (row['cat2_1']==row2['cat2_1']) or (row['cat2_2']==row2['cat2_2']):\n",
    "                if  (row['cat0_1']==row2['cat0_1']) or (row['cat0_2']==row2['cat0_2']) \\\n",
    "                 or (row['cat1_1']==row2['cat1_1']) or (row['cat1_2']==row2['cat1_2']) \\\n",
    "                or (row['cat2_1']==row2['cat2_1']) or (row['cat2_2']==row2['cat2_2']):\n",
    "                    \n",
    "                    x1=int(row['cat0_0']==row2['cat0_0'] )\n",
    "                    x2=int(row['cat0_1']==row2['cat0_1'] )\n",
    "                    x3=int(row['cat0_2']==row2['cat0_2'] )\n",
    "                    x4=int(row['cat1_0']==row2['cat1_0'] )\n",
    "                    x5=int(row['cat1_1']==row2['cat1_1'] )\n",
    "                    x6=int(row['cat1_2']==row2['cat1_2'] )\n",
    "                    x7=int(row['cat2_0']==row2['cat2_0'] )\n",
    "                    x8=int(row['cat2_1']==row2['cat2_1'] )\n",
    "                    x9=int(row['cat2_2']==row2['cat2_2'] )\n",
    "                    class_same_edge.append((index,index2))  #åŒå‘è¾¹ \n",
    "                    class_same_edge_attr.append((x1,x2,x3,x4,x5,x6,x7,x8,x9,   distance((row['latitude'],row['longitude']),(row2['latitude'],row2['longitude']))))\n",
    "\n",
    "    class_same_edge=np.array(class_same_edge)\n",
    "    class_same_edge=torch.tensor(class_same_edge,dtype=torch.long).t().contiguous()\n",
    "    return  class_same_edge, class_same_edge_attr\n",
    "\n",
    "class_same_edge,class_same_edge_attr=POi_class_same_POI(poi_data)\n",
    "np.save(\"../data/Multi-dimensional_Graphs/\"+city+\"/class_same_edge.npy\",class_same_edge)\n",
    "np.save(\"../data/Multi-dimensional_Graphs/\"+city+\"/class_same_edge_attr.npy\",class_same_edge_attr)\n",
    "\n",
    "class_same_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''å…±ç°è¾¹åˆå§‹åŒ–'''\n",
    "co_occurrence_list_index=[]  #å…¨é“¾æ¥ ç”¨æ¥åšåé¢çš„poi-poiä¹‹é—´è¾¹çš„ç‰¹å¾  æœ‰å‘å›¾ï¼Œå°±ç®—å…±çº¿ ä¹Ÿè¦è€ƒè™‘å‡ºç°é¡ºåº\n",
    "for i in range(poi_data.shape[0]):\n",
    "    for j in range(poi_data.shape[0]):\n",
    "        if i ==j:\n",
    "            continue\n",
    "        else:\n",
    "#             if (i,j) in co_occurrence_list_index or (j,i) in co_occurrence_list_index:\n",
    "#                 continue\n",
    "#             else:\n",
    "            co_occurrence_list_index.append((i,j))\n",
    "\n",
    "co_occurrence_list_index=sorted(list(set(co_occurrence_list_index))) #åªæ˜¯ç”¨äºåˆå§‹åŒ– åç»­è¦åˆ æ‰æ²¡æœ‰å…±ç°çš„poiè¾¹\n",
    "\n",
    "\n",
    "co_occurrence_list_dict_attr={} \n",
    "for (u_poi,v_poi) in co_occurrence_list_index:\n",
    "    index_co_occ=str(u_poi)+str(\"+\")+str(v_poi)\n",
    "    co_occurrence_list_dict_attr[index_co_occ]=[0,0] #co_occè¾¹çš„ç‰¹å¾ æœ‰ä¸¤ä¸ª å…±çº¿æ¬¡æ•°ä¸poiä¹‹é—´çš„è·ç¦»\n",
    "\n",
    "# print(co_occurrence_list_dict_attr)\n",
    "co_occurrence_list_index[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ç»Ÿè®¡ä¸¤ä¸¤èŠ‚ç‚¹ä¹‹é—´çš„å…±ç°æ¬¡æ•°   æ€»æ¯”ä¾‹ä¸º0.001792570896019172  \n",
    "check_in=check_in.sort_values('userid_index', ascending=True, inplace=False )  #å°†åŸå§‹çš„checkinæ ¹æ®poiæ’åº\n",
    "group2 = check_in.groupby(\"userid_index\")   #åˆ†ç»„\n",
    "group2=list(group2)\n",
    "for i in range(len(group2)):                 #æ¯ä¸€ä¸ªgroup2 éƒ½æ˜¯ç”¨æˆ·\n",
    "    if i%300==0:\n",
    "        print(i)\n",
    "    df=pd.DataFrame(group2[i][1])            #æ¯ä¸ªç”¨æˆ·çš„è®¿é—®è½¨è¿¹\n",
    "    df=df.reset_index(drop=True)\n",
    "    df_venu=sorted(set(list(df['Venue_id_index'])) ) #å»é‡  poiåˆ—è¡¨\n",
    "    df_venu_times={}                    #è®°å½•ä¸€ä¸ªpoiåœ¨ä¸€ä¸ªç”¨æˆ·è½¨è¿¹ä¸­å‡ºç°çš„æ¬¡æ•° \n",
    "    for i in range(len(df_venu)):\n",
    "        df_venu_times[df_venu[i]]=(list(df['Venue_id_index'])).count(df_venu[i])\n",
    "\n",
    "    for i in range(len(df_venu)):\n",
    "        for  j in range(i+1,len(df_venu)):\n",
    "            poi_poi=df_venu_times[df_venu[i]]*df_venu_times[df_venu[j]]\n",
    "            co_occurrence_list_dict_attr[str(i)+\"+\"+str(j)][0]+=poi_poi\n",
    "            co_occurrence_list_dict_attr[str(j)+\"+\"+str(i)][0]+=poi_poi\n",
    "\n",
    "co_occurrence_list_dict_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_list_dict_attr2={} #ä¿å­˜åªå­˜åœ¨å…±ç°å…³ç³»çš„è¾¹\n",
    "for x in co_occurrence_list_dict_attr.keys():\n",
    "    if co_occurrence_list_dict_attr[x][0]!=0: \n",
    "        co_occurrence_list_dict_attr2[x]= co_occurrence_list_dict_attr[x]\n",
    "for x in co_occurrence_list_dict_attr2.keys():\n",
    "    x2=x.split(\"+\", 1)\n",
    "    u=int(x2[0])\n",
    "    v=int(x2[-1])\n",
    "#     print((u,v))\n",
    "    dis=distance((poi_data.loc[u]['latitude'],poi_data.loc[u]['longitude']),(poi_data.loc[v]['latitude'],poi_data.loc[v]['longitude']))\n",
    "    co_occurrence_list_dict_attr2[x][1]=dis\n",
    "co_occurrence_list_dict_attr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_list_index2=[]\n",
    "co_occurrence_list_dict_attr3=[]\n",
    "for x in co_occurrence_list_dict_attr2.keys():\n",
    "    \n",
    "    x2=x.split(\"+\", 1)\n",
    "    attr=co_occurrence_list_dict_attr2[x]\n",
    "    co_occurrence_list_index2.append((int(x2[0]),int(x2[1])))\n",
    "    co_occurrence_list_dict_attr3.append(attr)\n",
    "# co_occurrence_list_index2\n",
    "\n",
    "np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/co_occurrence_list_index.npy\",torch.tensor(np.array(co_occurrence_list_index2)).t().contiguous())\n",
    "np.save(\"data/Multi-dimensional_Graphs/\"+city+\"/co_occurrence_attr.npy\",co_occurrence_list_dict_attr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
